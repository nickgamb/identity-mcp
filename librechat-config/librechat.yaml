version: 1.3.1

cache: true

# Set default endpoint and model
modelSpecs:
  enforce: false
  prioritize: true
  list:
    - name: "default"
      label: "GPT-OSS 20B"
      description: "GPT-OSS 20B"
      default: true
      preset:
        endpoint: "LocalOllama"
        model: "gpt-oss:20b"
        modelLabel: "gpt-oss:20b"
    - name: "gpt-oss-20b-finetuned"
      label: "GPT-OSS 20B (Fine-tuned)"
      description: "GPT-OSS 20B fine-tuned via Ollama (faster, requires merge script)"
      preset:
        endpoint: "LocalOllama"
        model: "gpt-oss-20b-finetuned"
        modelLabel: "gpt-oss-20b-finetuned"
    - name: "gpt-oss-20b-finetuned-hf"
      label: "GPT-OSS 20B (Fine-tuned HF)"
      description: "GPT-OSS 20B with LoRA adapter via HuggingFace (slower, dynamic loading)"
      preset:
        endpoint: "HFService"
        model: "gpt-oss-20b-finetuned"
        modelLabel: "gpt-oss-20b-finetuned"
    - name: "glm-4.5-air"
      label: "GLM-4.5-Air"
      description: "GLM-4.5-Air (no tools)"
      preset:
        endpoint: "LocalOllama"
        model: "glm-4.5-air"
        modelLabel: "glm-4.5-air"
    - name: "glm-with-tools"
      label: "GLM-4.5-Air (Tools)"
      description: "GLM-4.5-Air with tool support"
      preset:
        endpoint: "HFService"
        model: "glm-4.5-air"
        modelLabel: "glm-4.5-air"
    - name: "qwen3-32b"
      label: "Qwen3 32B"
      description: "Qwen3 32B"
      preset:
        endpoint: "LocalOllama"
        model: "qwen3:32b"
        modelLabel: "qwen3:32b"
    - name: "qwen3-30b-a3b"
      label: "Qwen3 30B-A3B"
      description: "Qwen3 30B-A3B"
      preset:
        endpoint: "LocalOllama"
        model: "qwen3:30b-a3b"
        modelLabel: "qwen3:30b-a3b"
    - name: "qwen2.5-32b"
      label: "Qwen2.5 32B"
      description: "Qwen2.5 32B"
      preset:
        endpoint: "LocalOllama"
        model: "qwen2.5:32b"
        modelLabel: "qwen2.5:32b"
    - name: "qwen2.5-14b"
      label: "Qwen2.5 14B"
      description: "Qwen2.5 14B"
      preset:
        endpoint: "LocalOllama"
        model: "qwen2.5:14b"
        modelLabel: "qwen2.5:14b"
    - name: "qwen2.5-7b"
      label: "Qwen2.5 7B"
      description: "Qwen2.5 7B"
      preset:
        endpoint: "LocalOllama"
        model: "qwen2.5:7b"
        modelLabel: "qwen2.5:7b"
    - name: "codellama-7b"
      label: "CodeLlama 7B"
      description: "CodeLlama 7B"
      preset:
        endpoint: "LocalOllama"
        model: "codellama:7b"
        modelLabel: "codellama:7b"
    - name: "deepseek-coder-6.7b"
      label: "DeepSeek Coder 6.7B"
      description: "DeepSeek Coder 6.7B"
      preset:
        endpoint: "LocalOllama"
        model: "deepseek-coder:6.7b"
        modelLabel: "deepseek-coder:6.7b"
    - name: "deepseek-r1"
      label: "DeepSeek R1"
      description: "DeepSeek R1 (reasoning model)"
      preset:
        endpoint: "LocalOllama"
        model: "deepseek-r1"
        modelLabel: "deepseek-r1"
    - name: "gemma2-9b"
      label: "Gemma 2 9B"
      description: "Gemma 2 9B (newer)"
      preset:
        endpoint: "LocalOllama"
        model: "gemma2:9b"
        modelLabel: "gemma2:9b"
    - name: "gemma2-27b"
      label: "Gemma 2 27B"
      description: "Gemma 2 27B"
      preset:
        endpoint: "LocalOllama"
        model: "gemma2:27b"
        modelLabel: "gemma2:27b"
    - name: "llama3.1-8b"
      label: "Llama 3.1 8B"
      description: "Llama 3.1 8B"
      preset:
        endpoint: "LocalOllama"
        model: "llama3.1:8b"
        modelLabel: "llama3.1:8b"
    - name: "llama3.1-70b"
      label: "Llama 3.1 70B"
      description: "Llama 3.1 70B (best quality)"
      preset:
        endpoint: "LocalOllama"
        model: "llama3.1:70b"
        modelLabel: "llama3.1:70b"
    - name: "llama3.2-3b"
      label: "Llama 3.2 3B"
      description: "Llama 3.2 3B (fast)"
      preset:
        endpoint: "LocalOllama"
        model: "llama3.2:3b"
        modelLabel: "llama3.2:3b"
    - name: "llama3.2-11b"
      label: "Llama 3.2 11B"
      description: "Llama 3.2 11B (balanced)"
      preset:
        endpoint: "LocalOllama"
        model: "llama3.2:11b"
        modelLabel: "llama3.2:11b"
    - name: "mistral-latest"
      label: "Mistral Latest"
      description: "Mistral Latest"
      preset:
        endpoint: "LocalOllama"
        model: "mistral:latest"
        modelLabel: "mistral:latest"
    - name: "mistral-nemo"
      label: "Mistral Nemo"
      description: "Mistral Nemo (12B)"
      preset:
        endpoint: "LocalOllama"
        model: "mistral-nemo"
        modelLabel: "mistral-nemo"
    - name: "mixtral-8x7b"
      label: "Mixtral 8x7B"
      description: "Mixtral 8x7B MoE"
      preset:
        endpoint: "LocalOllama"
        model: "mixtral:8x7b"
        modelLabel: "mixtral:8x7b"
    - name: "phi3.5-3.8b"
      label: "Phi-3.5 3.8B"
      description: "Phi-3.5 3.8B (newer)"
      preset:
        endpoint: "LocalOllama"
        model: "phi3.5:3.8b"
        modelLabel: "phi3.5:3.8b"
endpoints:
  custom:
    - name: "LocalOllama"
      apiKey: "ollama"
      baseURL: "http://ollama:11434/v1"
      models:
        default:
          - "gpt-oss:20b"
          - "gpt-oss-20b-finetuned"
          - "qwen3:30b-a3b"
          - "qwen3:32b"
          - "qwen2.5:32b"
          - "qwen2.5:14b"
          - "qwen2.5:7b"
          - "glm-4.5-air"
          - "codellama:7b"
          - "deepseek-coder:6.7b"
          - "deepseek-r1"
          - "gemma2:9b"
          - "gemma2:27b"
          - "llama3.1:8b"
          - "llama3.1:70b"
          - "llama3.2:3b"
          - "llama3.2:11b"
          - "mistral:latest"
          - "mistral-nemo"
          - "mixtral:8x7b"
          - "phi3.5:3.8b"
        fetch: true
      titleConvo: false
      titleModel: "gpt-oss:20b"
      summarize: false
      summaryModel: "gpt-oss:20b"
      forcePrompt: false
      modelDisplayLabel: "Local Ollama"
      temperature: 0.6
      max_tokens: 8192
      top_p: 0.9
      frequency_penalty: 0.0
      presence_penalty: 0.0
      context_length: 128000
  
    - name: "HFService"
      apiKey: "not-needed"
      baseURL: "http://hf-service:8000/v1"
      models:
        default:
          - "gpt-oss-20b"
          - "gpt-oss-20b-finetuned"
          - "glm-4.5-air"
        fetch: false
      titleConvo: false
      summarize: false
      forcePrompt: false
      modelDisplayLabel: "HuggingFace"
      temperature: 0.7
      max_tokens: 8192
      top_p: 0.9
      frequency_penalty: 0.0
      presence_penalty: 0.0
      context_length: 128000
  
  agents:
    recursionLimit: 50000
    maxRecursionLimit: 50000
    disableBuilder: false

mcpServers:
  identity-mcp:
    type: http
    url: http://mcp-server:4000/mcp-protocol
    timeout: 300000
    reconnect: true
    reconnectDelay: 2000
    maxReconnectAttempts: 10

