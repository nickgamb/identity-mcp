version: 1.3.1

cache: true

# Set default endpoint and model
modelSpecs:
  enforce: false
  prioritize: true
  list:
    - name: "default"
      label: "GPT-OSS 20B"
      description: "GPT-OSS 20B"
      default: true
      preset:
        endpoint: "LocalOllama"
        model: "gpt-oss:20b"
        modelLabel: "gpt-oss:20b"
    - name: "glm-4.5-air"
      label: "GLM-4.5-Air"
      description: "GLM-4.5-Air (no tools)"
      preset:
        endpoint: "LocalOllama"
        model: "glm-4.5-air"
        modelLabel: "glm-4.5-air"
    - name: "glm-with-tools"
      label: "GLM-4.5-Air (Tools)"
      description: "GLM-4.5-Air with tool support"
      preset:
        endpoint: "HFService"
        model: "glm-4.5-air"
        modelLabel: "glm-4.5-air"
    - name: "qwen3-32b"
      label: "Qwen3 32B"
      description: "Qwen3 32B"
      preset:
        endpoint: "LocalOllama"
        model: "qwen3:32b"
        modelLabel: "qwen3:32b"
    - name: "qwen3-30b-a3b"
      label: "Qwen3 30B-A3B"
      description: "Qwen3 30B-A3B"
      preset:
        endpoint: "LocalOllama"
        model: "qwen3:30b-a3b"
        modelLabel: "qwen3:30b-a3b"
    - name: "qwen2.5-32b"
      label: "Qwen2.5 32B"
      description: "Qwen2.5 32B"
      preset:
        endpoint: "LocalOllama"
        model: "qwen2.5:32b"
        modelLabel: "qwen2.5:32b"
    - name: "gpt-oss-20b"
      label: "GPT-OSS 20B"
      description: "GPT-OSS 20B"
      preset:
        endpoint: "LocalOllama"
        model: "gpt-oss:20b"
        modelLabel: "gpt-oss:20b"

endpoints:
  custom:
    - name: "LocalOllama"
      apiKey: "ollama"
      baseURL: "http://ollama:11434/v1"
      models:
        default:
          - "gpt-oss:20b"
          - "qwen3:30b-a3b"
          - "qwen3:32b"
          - "qwen2.5:32b"
          - "glm-4.5-air"
        fetch: true
      titleConvo: true
      titleModel: "qwen3:30b-a3b"
      summarize: false
      summaryModel: "qwen3:30b-a3b"
      forcePrompt: false
      modelDisplayLabel: "Local Ollama"
      temperature: 0.6
      max_tokens: 8192
      top_p: 0.9
      frequency_penalty: 0.0
      presence_penalty: 0.0
      context_length: 128000
  
    - name: "HFService"
      apiKey: "not-needed"
      baseURL: "http://hf-service:8000/v1"
      models:
        default:
          - "glm-4.5-air"
        fetch: false
      titleConvo: false
      summarize: false
      forcePrompt: false
      modelDisplayLabel: "HuggingFace"
      temperature: 0.7
      max_tokens: 2048
      top_p: 0.9
      frequency_penalty: 0.0
      presence_penalty: 0.0
      context_length: 128000
  
  agents:
    recursionLimit: 50000
    maxRecursionLimit: 50000
    disableBuilder: false

mcpServers:
  identity-mcp:
    type: http
    url: http://mcp-server:4000/mcp-protocol
    timeout: 300000
    reconnect: true
    reconnectDelay: 2000
    maxReconnectAttempts: 10

